{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling loading of the datasets (which comprehends computation of analysis variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from parameters_dict import physics_parameters\n",
    "from dark_nus_utils import load_datasets\n",
    "from plot_utils import set_plot_title, annotated_2d_plot\n",
    "from exp_analysis_class import exp_analysis, gamma_general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_exp_analyis = exp_analysis(hierarchy='light', D_or_M='majorana')\n",
    "m4, mz = 0.8, 0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading df base\n",
      "initialising df base\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 24.8933 s\n",
       "File: /n/home00/nfoppiani/projects/dark_nus/nicgen/exp_analysis/exp_analysis_class.py\n",
       "Function: load_df_base at line 102\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   102                                               def load_df_base(self, n_evt=1000000, filename=None):\n",
       "   103         1          5.0      5.0      0.0          self.n_evt = n_evt\n",
       "   104         1        475.0    475.0      0.0          print(\"loading df base\")\n",
       "   105         1          2.0      2.0      0.0          if filename is None:\n",
       "   106         1     244752.0 244752.0      1.0              self.df_base = pd.read_pickle(f'{self.base_folder}scan/{self.hierarchy}_{self.D_or_M}/{self.m4_limits[0]}_m4_{self.m4_limits[1]}_{self.mz_limits[0]}_mzprime_{self.mz_limits[1]}_nevt_{self.n_evt}.pckl')\n",
       "   107                                                   else:\n",
       "   108                                                       self.df_base = pd.read_pickle(filename)\n",
       "   109         1         95.0     95.0      0.0          print(\"initialising df base\")\n",
       "   110         1   24648020.0 24648020.0     99.0          self.initialise_df(self.df_base, which_scan='m4_mz')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f this_exp_analyis.load_df_base this_exp_analyis.load_df_base(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading df base\n",
      "initialising df base\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 23.6237 s\n",
       "File: /n/home00/nfoppiani/projects/dark_nus/nicgen/exp_analysis/exp_analysis_class.py\n",
       "Function: initialise_df at line 125\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   125                                               def initialise_df(self, df, which_scan=None):\n",
       "   126         1   16095581.0 16095581.0     68.1          self.compute_analysis_variables(df)\n",
       "   127         1     646202.0 646202.0      2.7          self.compute_actual_weights(df, which_scan)\n",
       "   128         1     708440.0 708440.0      3.0          self.compute_interaction_point(df)\n",
       "   129         1     269699.0 269699.0      1.1          self.unitary_decay_length(df)\n",
       "   130         1      31002.0  31002.0      0.1          self.compute_selection(df)\n",
       "   131                                                   \n",
       "   132                                                   # flatten index of pandas multiindex\n",
       "   133         1        474.0    474.0      0.0          df.columns = ['_'.join(col) if (col[1]!='') else col[0] for col in df.columns.values]\n",
       "   134         1    1631650.0 1631650.0      6.9          df.drop(droplist, axis=1, inplace=True)\n",
       "   135                                                   \n",
       "   136        40        182.0      4.5      0.0          for column in df.columns:\n",
       "   137        39       5705.0    146.3      0.0              if df[column].dtype == 'float':\n",
       "   138        27    4225882.0 156514.1     17.9                  df[column] = pd.to_numeric(df[column], downcast='float')\n",
       "   139                                                           \n",
       "   140         1          1.0      1.0      0.0          if which_scan == 'm4_mz':\n",
       "   141         1         70.0     70.0      0.0              self.m4_values = self.df_base['m4'].values\n",
       "   142         1         63.0     63.0      0.0              self.mz_values = self.df_base['mzprime'].values\n",
       "   143         1       8565.0   8565.0      0.0              self.m4mz_values = np.stack([self.m4_values, self.mz_values], axis=-1)\n",
       "   144         1        141.0    141.0      0.0              self.actual_weight_values = self.df_base['actual_weight'].values"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f this_exp_analyis.initialise_df this_exp_analyis.load_df_base(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading df base\n",
      "initialising df base\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 16.0883 s\n",
       "File: /n/home00/nfoppiani/projects/dark_nus/nicgen/exp_analysis/exp_analysis_class.py\n",
       "Function: compute_analysis_variables at line 146\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   146                                               @staticmethod\n",
       "   147                                               def compute_analysis_variables(df):\n",
       "   148         5         13.0      2.6      0.0          for comp in ['t','x','y','z']:\n",
       "   149         4     179609.0  44902.2      1.1              df['pee', comp] = df['plm', comp] + df['plp', comp]\n",
       "   150         4     327800.0  81950.0      2.0              df['pdark', comp] = df['plm', comp] + df['plp', comp] + df['pnu', comp]\n",
       "   151                                           \n",
       "   152         1    2047538.0 2047538.0     12.7          df['recoil_mass', ''] = inv_mass(df['pHad']).round(6)\n",
       "   153                                                   # e+e- cone vars\n",
       "   154         1     761626.0 761626.0      4.7          df['ee_mass', ''] = inv_mass(df['pee'])\n",
       "   155         1       7708.0   7708.0      0.0          df['ee_energy', ''] = df['pee', 't']\n",
       "   156         1     825101.0 825101.0      5.1          df['ee_momentum', ''] = np.sqrt(dot3_df(df['pee'], df['pee']))    \n",
       "   157         1      29688.0  29688.0      0.2          df['ee_energy_asymetry', ''] = (df['plm', 't']-df['plp', 't'])/(df['plp', 't']+df['plm', 't'])\n",
       "   158         1     941895.0 941895.0      5.9          df['ee_costheta', ''] = costheta(df['plm'], df['plp'])\n",
       "   159         1    1052128.0 1052128.0      6.5          df['ee_theta', ''] = np.arccos(costheta(df['plm'], df['plp']))\n",
       "   160         1     926607.0 926607.0      5.8          df['ee_beam_costheta', ''] = df['pee', 'z']/np.sqrt(dot3_df(df['pee'], df['pee']))\n",
       "   161         1    1035959.0 1035959.0      6.4          df['ee_beam_theta', ''] = np.arccos(df['pee', 'z']/np.sqrt(dot3_df(df['pee'], df['pee'])))\n",
       "   162                                                   # dark nu vars\n",
       "   163         1     970153.0 970153.0      6.0          df['nu_dark_beam_costheta', ''] = df['pdark', 'z']/np.sqrt(dot3_df(df['pdark'], df['pdark']))\n",
       "   164                                                   # e- vars        \n",
       "   165         1       7046.0   7046.0      0.0          df['em_energy', ''] = df['plm', 't']\n",
       "   166         1    1102255.0 1102255.0      6.9          df['em_beam_theta', ''] = np.arccos(df['plm', 'z']/np.sqrt(dot3_df(df['plm'], df['plm'])))\n",
       "   167         1    1126091.0 1126091.0      7.0          df['em_beam_costheta', ''] = np.arccos(df['plm', 'z']/np.sqrt(dot3_df(df['plm'], df['plm'])))\n",
       "   168                                                   # e+ vars        \n",
       "   169         1       7218.0   7218.0      0.0          df['ep_energy', ''] = df['plp', 't']\n",
       "   170         1    1169946.0 1169946.0      7.3          df['ep_beam_theta', ''] = np.arccos(df['plp', 'z']/np.sqrt(dot3_df(df['plp'], df['plp'])))\n",
       "   171         1    1193589.0 1193589.0      7.4          df['ep_beam_costheta', ''] = np.arccos(df['plp', 'z']/np.sqrt(dot3_df(df['plp'], df['plp'])))\n",
       "   172                                                   # high level vars\n",
       "   173         5      62826.0  12565.2      0.4          df['experimental_t', ''] = (df['plm','t'] - df['plm','z'] + df['plp','t'] - df['plp','z'])**2 +\\\n",
       "   174         4      23046.0   5761.5      0.1                                      df['plm','x']**2 + df['plm','y']**2 + df['plp','x']**2 + df['plp','y']**2\n",
       "   175                                                   \n",
       "   176         1    1144393.0 1144393.0      7.1          df['p3dark', ''] = np.sqrt(dot3_df(df['pdark'], df['pdark']))\n",
       "   177         1    1131029.0 1131029.0      7.0          df['mdark', ''] = inv_mass(df['pdark'])\n",
       "   178         1      15019.0  15019.0      0.1          df['betagamma', ''] = df['p3dark', '']/df['mdark', '']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f this_exp_analyis.compute_analysis_variables this_exp_analyis.load_df_base(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling another df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading df 0.4, 0.01\n",
      "initialising df 0.4, 0.01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 25.8782 s\n",
       "File: /n/home00/nfoppiani/projects/dark_nus/nicgen/exp_analysis/exp_analysis_class.py\n",
       "Function: load_df at line 112\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   112                                               def load_df(self, m4, mz):\n",
       "   113         1        304.0    304.0      0.0          print(f\"loading df {m4}, {mz}\")\n",
       "   114         1     253824.0 253824.0      1.0          self.dfs[(m4, mz)] = pd.read_pickle(f'{self.base_folder}m4_{m4}_mzprime_{mz}_{self.hierarchy}_{self.D_or_M}/MC_m4_{m4}_mzprime_{mz}.pckl')\n",
       "   115         1         87.0     87.0      0.0          print(f\"initialising df {m4}, {mz}\")\n",
       "   116         1   25623963.0 25623963.0     99.0          self.initialise_df(self.dfs[(m4, mz)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f this_exp_analyis.load_df this_exp_analyis.load_df(0.4, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading df 0.4, 0.01\n",
      "initialising df 0.4, 0.01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 25.5641 s\n",
       "File: /n/home00/nfoppiani/projects/dark_nus/nicgen/exp_analysis/exp_analysis_class.py\n",
       "Function: initialise_df at line 125\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   125                                               def initialise_df(self, df, which_scan=None):\n",
       "   126         1   17729000.0 17729000.0     69.4          self.compute_analysis_variables(df)\n",
       "   127         1     383401.0 383401.0      1.5          self.compute_actual_weights(df, which_scan)\n",
       "   128         1     844931.0 844931.0      3.3          self.compute_interaction_point(df)\n",
       "   129         1     303545.0 303545.0      1.2          self.unitary_decay_length(df)\n",
       "   130         1      32319.0  32319.0      0.1          self.compute_selection(df)\n",
       "   131                                                   \n",
       "   132                                                   # flatten index of pandas multiindex\n",
       "   133         1        502.0    502.0      0.0          df.columns = ['_'.join(col) if (col[1]!='') else col[0] for col in df.columns.values]\n",
       "   134         1    1730148.0 1730148.0      6.8          df.drop(droplist, axis=1, inplace=True)\n",
       "   135                                                   \n",
       "   136        40        181.0      4.5      0.0          for column in df.columns:\n",
       "   137        39       5745.0    147.3      0.0              if df[column].dtype == 'float':\n",
       "   138        27    4534293.0 167936.8     17.7                  df[column] = pd.to_numeric(df[column], downcast='float')\n",
       "   139                                                           \n",
       "   140         1          1.0      1.0      0.0          if which_scan == 'm4_mz':\n",
       "   141                                                       self.m4_values = self.df_base['m4'].values\n",
       "   142                                                       self.mz_values = self.df_base['mzprime'].values\n",
       "   143                                                       self.m4mz_values = np.stack([self.m4_values, self.mz_values], axis=-1)\n",
       "   144                                                       self.actual_weight_values = self.df_base['actual_weight'].values"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f this_exp_analyis.initialise_df this_exp_analyis.load_df(0.4, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading df 0.4, 0.01\n",
      "initialising df 0.4, 0.01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 17.7265 s\n",
       "File: /n/home00/nfoppiani/projects/dark_nus/nicgen/exp_analysis/exp_analysis_class.py\n",
       "Function: compute_analysis_variables at line 146\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   146                                               @staticmethod\n",
       "   147                                               def compute_analysis_variables(df):\n",
       "   148         5         13.0      2.6      0.0          for comp in ['t','x','y','z']:\n",
       "   149         4     190352.0  47588.0      1.1              df['pee', comp] = df['plm', comp] + df['plp', comp]\n",
       "   150         4     345103.0  86275.8      1.9              df['pdark', comp] = df['plm', comp] + df['plp', comp] + df['pnu', comp]\n",
       "   151                                           \n",
       "   152         1    2196953.0 2196953.0     12.4          df['recoil_mass', ''] = inv_mass(df['pHad']).round(6)\n",
       "   153                                                   # e+e- cone vars\n",
       "   154         1     831692.0 831692.0      4.7          df['ee_mass', ''] = inv_mass(df['pee'])\n",
       "   155         1       6680.0   6680.0      0.0          df['ee_energy', ''] = df['pee', 't']\n",
       "   156         1     924278.0 924278.0      5.2          df['ee_momentum', ''] = np.sqrt(dot3_df(df['pee'], df['pee']))    \n",
       "   157         1      35941.0  35941.0      0.2          df['ee_energy_asymetry', ''] = (df['plm', 't']-df['plp', 't'])/(df['plp', 't']+df['plm', 't'])\n",
       "   158         1    1064403.0 1064403.0      6.0          df['ee_costheta', ''] = costheta(df['plm'], df['plp'])\n",
       "   159         1    1183083.0 1183083.0      6.7          df['ee_theta', ''] = np.arccos(costheta(df['plm'], df['plp']))\n",
       "   160         1    1030276.0 1030276.0      5.8          df['ee_beam_costheta', ''] = df['pee', 'z']/np.sqrt(dot3_df(df['pee'], df['pee']))\n",
       "   161         1    1143983.0 1143983.0      6.5          df['ee_beam_theta', ''] = np.arccos(df['pee', 'z']/np.sqrt(dot3_df(df['pee'], df['pee'])))\n",
       "   162                                                   # dark nu vars\n",
       "   163         1    1076816.0 1076816.0      6.1          df['nu_dark_beam_costheta', ''] = df['pdark', 'z']/np.sqrt(dot3_df(df['pdark'], df['pdark']))\n",
       "   164                                                   # e- vars        \n",
       "   165         1       7220.0   7220.0      0.0          df['em_energy', ''] = df['plm', 't']\n",
       "   166         1    1216800.0 1216800.0      6.9          df['em_beam_theta', ''] = np.arccos(df['plm', 'z']/np.sqrt(dot3_df(df['plm'], df['plm'])))\n",
       "   167         1    1239660.0 1239660.0      7.0          df['em_beam_costheta', ''] = np.arccos(df['plm', 'z']/np.sqrt(dot3_df(df['plm'], df['plm'])))\n",
       "   168                                                   # e+ vars        \n",
       "   169         1       7135.0   7135.0      0.0          df['ep_energy', ''] = df['plp', 't']\n",
       "   170         1    1287319.0 1287319.0      7.3          df['ep_beam_theta', ''] = np.arccos(df['plp', 'z']/np.sqrt(dot3_df(df['plp'], df['plp'])))\n",
       "   171         1    1313810.0 1313810.0      7.4          df['ep_beam_costheta', ''] = np.arccos(df['plp', 'z']/np.sqrt(dot3_df(df['plp'], df['plp'])))\n",
       "   172                                                   # high level vars\n",
       "   173         5      76338.0  15267.6      0.4          df['experimental_t', ''] = (df['plm','t'] - df['plm','z'] + df['plp','t'] - df['plp','z'])**2 +\\\n",
       "   174         4      27245.0   6811.2      0.2                                      df['plm','x']**2 + df['plm','y']**2 + df['plp','x']**2 + df['plp','y']**2\n",
       "   175                                                   \n",
       "   176         1    1264597.0 1264597.0      7.1          df['p3dark', ''] = np.sqrt(dot3_df(df['pdark'], df['pdark']))\n",
       "   177         1    1241968.0 1241968.0      7.0          df['mdark', ''] = inv_mass(df['pdark'])\n",
       "   178         1      14839.0  14839.0      0.1          df['betagamma', ''] = df['p3dark', '']/df['mdark', '']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f this_exp_analyis.compute_analysis_variables this_exp_analyis.load_df(0.4, 0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dark_nus]",
   "language": "python",
   "name": "conda-env-dark_nus-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
